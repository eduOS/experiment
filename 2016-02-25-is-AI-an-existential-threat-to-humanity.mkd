---
layout: writing
title: Is AI an existential threat to humanity?
description: Some people think that artificial intelligence is important to the development of society, while others think that it has negative effects on society. Discuss both these views and give your opinion.
tags: writing, experiment
---

AI is replacing more and more of our jobs, and it's imaginable that they will be omnipresent and omnipotent to threaten our life.

First, people will face with job-threatening. with the machines become more and more intelligent and hence employable humans will need not apply. We see that it's happening, Amazon is replacing FedEx, Watson is replacing doctors and etc. Many people argue that AI industry will create many jobs for humans, but since cars replaced horses, we have not created as much jobs for them, we are like horse now and all our jobs in the last century will be taken over by machines, at lease almost all professional, white-collar and low skilled jobs. As a result, humans will be not important. Who wants to be useless and unemployable? Once served by robots we may drop into anarchy.

Second, AI would be omnipotent and immoral. In this trend and as the technology advances, machines are destined to be all-powerful. Many people argue that it's kind of impossible, but in the 1980s, the AI winter, many people just were down on AI as well. We can be certain that strong AI is possible. And AI is immoral, as Weizenbaum said. How horrible will they be?

Let's take some examples, with the ability of free-floating on the internet, they may connect to other robots; they update themselves automatically. And their superpower and super-intelligence is not a matter but that they'll be smart enough to have different will and go and finally fight against our stupid human is. Therefore, it's possible although difficult.

Third, humanity would face life-threatening. Because AI would kill us directly or indirectly. Stephen Hawking, "humans, who are limited by slow biological evolution, couldn't compete and would be superseded.” Elon Musk, ”just like the way we treat other creatures.” Maybe just maybe they may not kill us directly but a massive asteroid strike, a nearby supernova or gamma ray burst, a massive shift in the climate knocking out world food production, an extremely virulent virus, Global thermonuclear war made by them would kill us. AI may won't go wild but human who own them may. That is to say,only a small chance of threatening leads to the whole human disaster or extinction.

In general, to prevent such a disaster, the government should make laws to stop the nowadays research on AI as they did for human clone, otherwise will drop into an unfathomable death hell.

...........................     
Welcome proofreading help and language suggestions. Tons of thanks in advance.

